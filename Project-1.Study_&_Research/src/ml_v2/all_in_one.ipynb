{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      Single Epithelial Cell Size  Bare Nuclei  Bland Chromatin  \\\n",
      "82                      -0.549168            0        -0.179534   \n",
      "51                      -0.549168            0        -0.179534   \n",
      "220                     -0.549168            0        -0.179534   \n",
      "559                     -0.549168            0        -0.589645   \n",
      "544                     -0.549168            0        -0.589645   \n",
      "\n",
      "     Clump Thickness  Marginal Adhesion   Mitoses  Normal Nucleoli  \\\n",
      "82          0.206788          -0.632794 -0.343666        -0.611387   \n",
      "51          0.206788           0.417854 -0.343666         0.371049   \n",
      "220        -1.213798          -0.282578 -0.343666        -0.611387   \n",
      "559         0.206788          -0.632794 -0.343666        -0.611387   \n",
      "544        -0.858651          -0.282578 -0.343666        -0.611387   \n",
      "\n",
      "     Uniformity of Cell Shape  Uniformity of Cell Size  \n",
      "82                  -0.742767                -0.371782  \n",
      "51                  -0.069800                -0.044070  \n",
      "220                 -0.742767                -0.699494  \n",
      "559                 -0.742767                -0.699494  \n",
      "544                 -0.069800                -0.699494  \n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import accuracy_score, f1_score, confusion_matrix, classification_report\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.naive_bayes import GaussianNB \n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "\n",
    "\n",
    "df = pd.read_csv('./data/original_csv.csv')\n",
    "\n",
    "# fill missing values with mean column values\n",
    "df.fillna(df.mean(), inplace=True)\n",
    "\n",
    "#replace value in class column\n",
    "df['class'] = df['class'].replace(['class1', 'class2'], [0, 1])\n",
    "#df.head()\n",
    "\n",
    "X = df.drop('class', axis=1)\n",
    "y = df['class']\n",
    "#print(X.head())\n",
    "\n",
    "#normalize data\n",
    "X = (X - X.mean()) / X.std()\n",
    "y = y\n",
    "\n",
    "#replace NaN with 0\n",
    "X = X.fillna(0)\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "print(X_train.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "KNeighborsClassifier()\n",
      "accuracy score:  0.9714285714285714\n",
      "f1 score:  0.9715871547508921\n",
      "LogisticRegression(max_iter=1000, multi_class='multinomial', random_state=0)\n",
      "accuracy score:  0.9571428571428572\n",
      "f1 score:  0.9568790584415585\n",
      "DecisionTreeClassifier(random_state=0)\n",
      "accuracy score:  0.9285714285714286\n",
      "f1 score:  0.9285714285714286\n",
      "RandomForestClassifier(max_features='auto')\n",
      "accuracy score:  0.9642857142857143\n",
      "f1 score:  0.9643874643874644\n",
      "SVC(gamma='auto')\n",
      "accuracy score:  0.9642857142857143\n",
      "f1 score:  0.9643874643874644\n",
      "GaussianNB()\n",
      "accuracy score:  0.9642857142857143\n",
      "f1 score:  0.9643874643874644\n",
      "MLPClassifier()\n",
      "accuracy score:  0.9714285714285714\n",
      "f1 score:  0.9714285714285714\n",
      "GaussianNB()\n",
      "accuracy score:  0.9642857142857143\n",
      "f1 score:  0.9643874643874644\n"
     ]
    }
   ],
   "source": [
    "#Initialize classifier\n",
    "clf0 = KNeighborsClassifier(n_neighbors=5, \n",
    "                            weights='uniform', \n",
    "                            algorithm='auto', \n",
    "                            leaf_size=30, \n",
    "                            p=2, \n",
    "                            metric='minkowski', \n",
    "                            metric_params=None, \n",
    "                            n_jobs=None)\n",
    "clf1 = LogisticRegression(random_state=0, \n",
    "                            solver='lbfgs', \n",
    "                            multi_class='multinomial', \n",
    "                            max_iter=1000)\n",
    "clf2 = DecisionTreeClassifier(random_state=0, \n",
    "                                criterion='gini', \n",
    "                                splitter='best', \n",
    "                                max_depth=None, \n",
    "                                min_samples_split=2, \n",
    "                                min_samples_leaf=1, \n",
    "                                min_weight_fraction_leaf=0.0, \n",
    "                                max_features=None, \n",
    "                                max_leaf_nodes=None, \n",
    "                                min_impurity_decrease=0.0,\n",
    "                                class_weight=None)\n",
    "clf3 = RandomForestClassifier(n_estimators=100,\n",
    "                                criterion='gini', \n",
    "                                max_depth=None, \n",
    "                                min_samples_split=2, \n",
    "                                min_samples_leaf=1, \n",
    "                                min_weight_fraction_leaf=0.0, \n",
    "                                max_features='auto', \n",
    "                                max_leaf_nodes=None, \n",
    "                                bootstrap=True, \n",
    "                                oob_score=False, \n",
    "                                n_jobs=None, \n",
    "                                random_state=None, \n",
    "                                verbose=0, \n",
    "                                warm_start=False, \n",
    "                                class_weight=None)\n",
    "clf4 = SVC(gamma='auto',\n",
    "            kernel='rbf', \n",
    "            C=1.0, \n",
    "            degree=3, \n",
    "            coef0=0.0, \n",
    "            shrinking=True, \n",
    "            probability=False,\n",
    "            tol=0.001,\n",
    "            cache_size=200,\n",
    "            class_weight=None,\n",
    "            verbose=False,\n",
    "            max_iter=-1,\n",
    "            decision_function_shape='ovr',\n",
    "            break_ties=False,\n",
    "            random_state=None)\n",
    "clf5 = GaussianNB()\n",
    "clf6 = MLPClassifier(hidden_layer_sizes=(100, ),\n",
    "                    activation='relu',\n",
    "                    solver='adam',\n",
    "                    alpha=0.0001,\n",
    "                    batch_size='auto',\n",
    "                    learning_rate='constant',\n",
    "                    learning_rate_init=0.001,\n",
    "                    power_t=0.5,\n",
    "                    max_iter=200,\n",
    "                    shuffle=True,\n",
    "                    random_state=None,\n",
    "                    tol=0.0001,\n",
    "                    verbose=False,\n",
    "                    warm_start=False,\n",
    "                    momentum=0.9,\n",
    "                    nesterovs_momentum=True,\n",
    "                    early_stopping=False,\n",
    "                    validation_fraction=0.1,\n",
    "                    beta_1=0.9,\n",
    "                    beta_2=0.999,\n",
    "                    epsilon=1e-08,\n",
    "                    n_iter_no_change=10)\n",
    "clf7 = GaussianNB()\n",
    "\n",
    "models = [clf0, clf1, clf2, clf3, clf4, clf5, clf6, clf7]\n",
    "\n",
    "for model in models:\n",
    "    model.fit(X_train, y_train)\n",
    "    y_pred = model.predict(X_test)\n",
    "    accuracy = accuracy_score(y_test, y_pred)\n",
    "    f1 = f1_score(y_test, y_pred, average='weighted')\n",
    "    print(model)\n",
    "    print(\"accuracy score: \", accuracy)\n",
    "    print(\"f1 score: \", f1)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.6 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "b0fa6594d8f4cbf19f97940f81e996739fb7646882a419484c72d19e05852a7e"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
